# Recommended Models and Upscalers

This document outlines the recommended AI models and open-source upscalers for a hobbyist GPU setup (~12–16 GB VRAM) for creating text, video, audio, music, and image content.

## Recommended Models

### **Text (Planning, Scripts, RAG for textbooks)**
- **Model:** LLaMA 3 8B  
- **Description:** High-quality full scripts and structured storytelling.  
- **Hardware:** Fits on ~12–16 GB GPU (single GPU friendly).  
- **Notes:** Handles medium-length context well.  

### **Video Generation (Cinematic-ish 720p–1080p short clips)**
- **Model:** Wan 2.1 14B (medium/small version)  
- **Description:** Small version (1.3B–14B) can generate 480–720p clips.  
- **Hardware:** ~12 GB GPU.  
- **Notes:** Can upscale to 1080p via ESRGAN / AI upscalers; good balance of quality vs VRAM use.  

### **Audio Speech / Narration**
- **Model:** Orpheus 3B  
- **Description:** Multi-lingual TTS with guided emotion.  
- **Hardware:** Fits on ~12 GB GPU.  
- **Notes:** Offers expressive narration without needing larger models like Higgs V2 (16–24 GB VRAM).  

### **Audio Music / SFX**
- **Model:** MusicGen 1.5B (medium)  
- **Description:** Text-to-music model producing cinematic-style audio.  
- **Hardware:** ~12 GB GPU.  
- **Notes:** Great for short emotional background tracks.  

### **Image / Thumbnail Generation**
- **Model:** Stable Diffusion XL (SDXL)  
- **Description:** High-quality thumbnails at 512–768 px.  
- **Hardware:** 8–12 GB GPU.  
- **Notes:** Best balance of quality and VRAM for hobbyist hardware; can be upscaled to 1080p or 4K.

## Open-Source Upscalers for Images / Video Frames

### **Real-ESRGAN**
- **Type:** GAN-based super-resolution  
- **Open-source:** [GitHub](https://github.com/xinntao/Real-ESRGAN)  
- **Hardware:** 8–12 GB GPU for 512–768 px → 1080p; 12–16 GB recommended for 4K  
- **Notes:** Excellent for faces, objects, and general image fidelity; widely used for SDXL outputs.  

### **ESRGAN (Original / Enhanced)**
- **Type:** GAN-based super-resolution  
- **Open-source:** [GitHub](https://github.com/xinntao/ESRGAN)  
- **Hardware:** Similar to Real-ESRGAN; slightly older, lighter VRAM usage  
- **Notes:** Suitable for images and video frames; lightweight enough for hobbyist GPUs.  

### **SwinIR (Image Restoration Transformer)**
- **Type:** Transformer-based super-resolution  
- **Open-source:** [GitHub](https://github.com/JingyunLiang/SwinIR)  
- **Hardware:** ~8–12 GB VRAM for 512–768 px → 1080p; ~16 GB for 4K  
- **Notes:** Produces sharp edges; great for architectural or detailed renders.  

### **Real-CUGAN**
- **Type:** GAN-based, optimized for real-world images  
- **Open-source:** [GitHub (NCNN/Vulkan version)](https://github.com/nihui/realsr-ncnn-vulkan)  
- **Hardware:** Very efficient; 6–12 GB GPU  
- **Notes:** Fast inference, high-quality output; Vulkan backend helps on Windows/WSL.  

### **Video2X / Waifu2X (Video Upscaling)**
- **Type:** Multi-frame / image sequence upscaler (uses ESRGAN or SRGAN)  
- **Open-source:** [GitHub](https://github.com/k4yt3x/video2x)  
- **Hardware:** ~8–12 GB GPU for 720p → 1080p  
- **Notes:** Ideal for video clips generated by Wan 2.1; can batch upscale frames efficiently.  

### **EDVR (Enhanced Deformable Video Restoration)**
- **Type:** Video super-resolution / restoration  
- **Open-source:** [GitHub](https://github.com/xinntao/EDVR)  
- **Hardware:** 12 GB+ GPU for 720p → 1080p; 16 GB+ for 4K sequences  
- **Notes:** Specifically designed for video; maintains temporal consistency across frames.



I want to get the following recommended models up and running on my wsl system. I should have my intel arc gpu available for usage, i would prefer to use ollama's environment to run models but let me know if i need another platform to run a model. Please help me setup the recommended models for whatever is optimal for original generation, then upscaling to get 1080p or 4k output at 30fps. I want to use the intel arc gpu for all of this. I would like clear an concise steps to get this done.